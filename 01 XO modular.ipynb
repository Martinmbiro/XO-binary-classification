{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNFL6RWm90upIWuHjv8rWgh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Martinmbiro/XO-binary-classification/blob/main/01%20XO%20modular.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Implementing Modules**\n",
        "> In this notebook, I'll be creating modules for the most reusable code from one of my previous GitHub repositories: [`Pytorch computer vision basics`](https://github.com/Martinmbiro/Pytorch-computer-vision-basics/blob/main/04%20Implementing%20TinyVGG%20model%20architecture.ipynb)\n",
        "\n",
        "> 💎 **Pro Tip**\n",
        "+ Modules help organize code logically, promote code reusability and cleaner code"
      ],
      "metadata": {
        "id": "oy7q2jVQeETI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> 📝 **Note**  \n",
        "+ All the steps we followed in the notebook linked above remain the same, except the neural network I'll be using here (since it's a binary classification problem)\n",
        "+ To **write** a code cell's content into a `*.py`, file we'll use the _magic command_ `%%writefile filename.py`\n",
        "+ To **append** a code cell's content into a `*.py`, file we'll use the _magic command_ `%%writefile -a filename.py`"
      ],
      "metadata": {
        "id": "e3jomjN-gGxs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ttjz2vF_8aKJ",
        "outputId": "cb809803-be1b-4203-b3d1-e5d6a8e78e97"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch version: 2.6.0+cu124\n",
            "torchvison version: 0.21.0+cu124\n"
          ]
        }
      ],
      "source": [
        "import torch, torchvision\n",
        "\n",
        "print(f'torch version: {torch.__version__}')\n",
        "print(f'torchvison version: {torchvision.__version__}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load the data\n",
        "> First, we'll create a directory to hold all the custom modules we write\n",
        "+ To create directories, we'll make use of the [`pathlib`](https://docs.python.org/3/library/pathlib.html) python module"
      ],
      "metadata": {
        "id": "_rIsjXcQgfjK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "modules_dir = Path('helper_modules')\n",
        "modules_dir.mkdir(parents=True, exist_ok=True)"
      ],
      "metadata": {
        "id": "ZR0x4--Vastx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Next, we'll define a function that filters `X` and `O` images from the [`EMNIST`](https://pytorch.org/vision/main/generated/torchvision.datasets.EMNIST.html) dataset. The function will return:\n",
        "+ `train_dl` - A `Dataloader` for training `Dataset`\n",
        "+ `test_dl` - A `Dataloader` for test `Dataset`\n",
        "+ `y_true` - A `ndarray` of true class labels from test `Dataset`\n",
        "+ `label_map` - A `dict` mapping class indices to class names"
      ],
      "metadata": {
        "id": "2nN2HBCOa02c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile helper_modules/data_loader.py\n",
        "\"\"\"\n",
        "Contains functionality for creating DataLoaders from EMNIST dataset\n",
        "\"\"\"\n",
        "import torch, numpy as np, os\n",
        "import torchvision.transforms as T\n",
        "from torch.utils.data import Subset, DataLoader, Dataset\n",
        "from torchvision import datasets\n",
        "\n",
        "# batch size and num_workers\n",
        "BATCH_SIZE = 32\n",
        "NUM_WORKERS = os.cpu_count()\n",
        "\n",
        "def create_dataloaders() -> tuple[DataLoader, DataLoader, np.ndarray, dict]:\n",
        "  \"\"\"Creates training and testing DataLoaders of the EMNIST dataset (for X and O only).\n",
        "  Also, returns y_true as well as a dictionary mapping indices to labels (for X and 0)\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "    train_dl: torch.utils.data.Dataloader\n",
        "          Training DataLoader\n",
        "\n",
        "    test_dl: torch.utils.data.Dataloader\n",
        "          Testing DataLoader\n",
        "\n",
        "    y_true: np.ndarray\n",
        "          An ndarray of true labels from the test Subset that was used to create testing DataLoader\n",
        "\n",
        "    label_map: dict\n",
        "          A dictionary mapping index to classes\n",
        "  \"\"\"\n",
        "  # class to warp around a Subset\n",
        "  class set_wrapper(Dataset):\n",
        "    def __init__(self, subset:Subset):\n",
        "      self.subset = subset\n",
        "\n",
        "    def __len__(self):\n",
        "      return len(self.subset)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "      # get image and label at specified index\n",
        "      x, y = self.subset[index]\n",
        "      # transform label 15 -> 0 and 24 -> 1\n",
        "      y = 0 if y==15 else 1\n",
        "      return x, y\n",
        "\n",
        "  # get the original dataset\n",
        "  train_data = datasets.EMNIST(\n",
        "      root='data', download=True, train=True, split='letters', transform=T.ToTensor())\n",
        "  test_data = datasets.EMNIST(\n",
        "      root='data', download=True, train=False, split='letters', transform=T.ToTensor())\n",
        "  # label_map\n",
        "  label_map = {0:'O', 1:'X'}\n",
        "\n",
        "  # get indices for train and test data (where target==24 | target==15)\n",
        "  train_indices = np.where((train_data.targets == 24) | (train_data.targets == 15))[0]\n",
        "  test_indices = np.where((test_data.targets == 24) | (test_data.targets == 15))[0]\n",
        "  np.random.shuffle(test_indices) # shuffle test_indices\n",
        "\n",
        "  # from indices gotten above, create subsets for train and test\n",
        "  train_set = Subset(dataset=train_data, indices=train_indices)\n",
        "  test_set = Subset(dataset=test_data, indices=test_indices)\n",
        "\n",
        "  # from the subsets above, wrap in custom set_wrapper class\n",
        "  train_dataset, test_dataset = set_wrapper(train_set), set_wrapper(test_set)\n",
        "\n",
        "  # get the targets from test Subset\n",
        "  y_true = list()\n",
        "  for x in range(len(test_set)):\n",
        "    _, y = test_set[x]\n",
        "    y_true.append(y)\n",
        "  # turn targets (15 and 24 into 0 and 1 respectively)\n",
        "  y_true = [0 if x==15 else 1 for x in y_true]\n",
        "  # turn the targets list into a numpy array\n",
        "  y_true = np.array(y_true)\n",
        "\n",
        "  # create train and test DataLoaders from the Subsets created above\n",
        "  train_dl = DataLoader(\n",
        "    dataset=train_dataset, batch_size=BATCH_SIZE,\n",
        "    num_workers=NUM_WORKERS, pin_memory=True, shuffle=True)\n",
        "\n",
        "  test_dl = DataLoader(\n",
        "    dataset=test_dataset, batch_size=BATCH_SIZE,\n",
        "    num_workers=NUM_WORKERS, pin_memory=True, shuffle=False)\n",
        "\n",
        "  # return\n",
        "  return train_dl, test_dl, y_true, label_map"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3L_JXUBJa2SW",
        "outputId": "f93ec71f-1338-422a-e7bd-07076a2204a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing helper_modules/data_loader.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build the [`TinyVGG`](https://www.youtube.com/watch?v=HnWIHWFbuUQ) architecture\n",
        "> Basically, the original `TinyVGG` network consists of two _convolutional_ blocks and a _classifier_ block\n",
        "+ Each _convolutional_ block consists of two [`nn.Conv2d`](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d) with `10` `out_channels`, two [`nn.ReLU`](https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html#torch.nn.ReLU) activations for non-linearity and a [`nn.MaxPool2d`](https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html#torch.nn.MaxPool2d) layer\n",
        "+ The _classifier_ block consists of one [`nn.Flatten`](https://pytorch.org/docs/stable/generated/torch.nn.Flatten.html#torch.nn.Flatten) and a [`nn.Linear`](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear) for classification\n",
        "\n",
        "> The function defined here will return a `model`, `Optimizer` and `loss function`\n"
      ],
      "metadata": {
        "id": "ntPc2qkqe0Cs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> 📝 **Note**\n",
        "\n",
        "> I'll be making a few modification to the original `TinyVGG` architecture as follows:\n",
        "+ The number of `out_channels` begins at `64` for the first `nn.Conv2d` layer and doubles for each subsequent `nn.Conv2d` layer\n",
        "+ An [`nn.BatchNorm2d`](https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm2d.html#torch.nn.BatchNorm2d) layer after each `nn.Conv2d` layer, but before the `nn.ReLU` non-linear activation\n",
        "+ An [`nn.BatchNorm1d`](https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm1d.html#torch.nn.BatchNorm1d) layer after the `nn.Flatten` and first `nn.Linear` layer in the `classifier` block\n",
        "+ An [`nn.Dropout`](https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html#torch.nn.Dropout) layer just before the output layer of the `classifier` block\n",
        "+ Also, we'll use [`torch.optim.SGD`](https://pytorch.org/docs/stable/generated/torch.optim.SGD.html#torch.optim.SGD) as optimizer and [`torch.nn.CrossEntropyLoss`](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html#crossentropyloss) as loss function, since this is a multi-class classification problem\n"
      ],
      "metadata": {
        "id": "-tkHX16-fPSJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile helper_modules/model_builder.py\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.optim import SGD\n",
        "\n",
        "def get_model(device:str) -> tuple[nn.Module, torch.optim.Optimizer, nn.Module]:\n",
        "  \"\"\"A function that returns a model, optimizer and loss function\n",
        "\n",
        "  Parameters\n",
        "  -------\n",
        "    device: str\n",
        "        The device on which to perform computation\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "    model: torch.nn.Module\n",
        "        A TinyVGG architecture model\n",
        "\n",
        "    opt: torch.Optimizer\n",
        "        An optimizer\n",
        "\n",
        "    loss_fn: torch.nn.Module\n",
        "        A loss function for multi-class classification\n",
        "  \"\"\"\n",
        "  torch.manual_seed(42)\n",
        "  torch.cuda.manual_seed(42)\n",
        "  # define model\n",
        "  class TinyVGG(nn.Module):\n",
        "    def __init__(self):\n",
        "      super().__init__()\n",
        "      # conv_block1\n",
        "      self.conv_b1 = nn.Sequential(\n",
        "          nn.Conv2d(in_channels=1, out_channels=64, kernel_size=3, padding=1),\n",
        "          nn.BatchNorm2d(64),\n",
        "          nn.ReLU(),\n",
        "          nn.Conv2d(64, 128, 3, padding=1),\n",
        "          nn.BatchNorm2d(128),\n",
        "          #nn.Dropout(p=0.15),\n",
        "          nn.ReLU(),\n",
        "          nn.MaxPool2d(kernel_size=2))\n",
        "\n",
        "      # conv_block2\n",
        "      self.conv_b2 = nn.Sequential(\n",
        "          nn.Conv2d(128, 256, 3, padding=1),\n",
        "          nn.BatchNorm2d(256),\n",
        "          nn.ReLU(),\n",
        "          nn.Conv2d(256, 512, 3, padding=1),\n",
        "          nn.BatchNorm2d(512),\n",
        "          # nn.Dropout(p=0.15),\n",
        "          nn.ReLU(),\n",
        "          nn.MaxPool2d(kernel_size=2))\n",
        "\n",
        "      # classifier\n",
        "      self.classifier = nn.Sequential(\n",
        "          nn.Flatten(),\n",
        "          nn.BatchNorm1d(25088),\n",
        "          nn.Linear(in_features=25088, out_features=256),\n",
        "          nn.BatchNorm1d(256),\n",
        "          nn.Dropout(p=0.05), # droput regularization\n",
        "          nn.Linear(256, 2))\n",
        "\n",
        "    def forward(self, x):\n",
        "      return self.classifier(self.conv_b2(self.conv_b1(x)))\n",
        "\n",
        "  # get an object of the model\n",
        "  model = TinyVGG().to(device)\n",
        "\n",
        "  # optimizer\n",
        "  '''opt = torch.optim.Adam(params=model.parameters(),\n",
        "                         lr=0.0009) # learning rate'''\n",
        "  # optimizer\n",
        "  opt = torch.optim.SGD(\n",
        "      params=model.parameters(),\n",
        "      lr=0.0001,  # learning rate\n",
        "      momentum=0.5) #\n",
        "\n",
        "  # loss_function\n",
        "  loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "  return model, opt, loss_fn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5NMT4NdOe29B",
        "outputId": "98f266d6-4162-42a5-86da-d3abd7d5e9b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing helper_modules/model_builder.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Early stopping\n",
        "> 💎 **Pro Tip**\n",
        "\n",
        "> [Early stopping](https://www.linkedin.com/advice/1/what-benefits-drawbacks-early-stopping#:~:text=Early%20stopping%20is%20a%20form,to%20increase%20or%20stops%20improving.) is a mechanism of stopping training when the validation loss stops improving; with a view to preventing _overfitting_ on the training data\n",
        "+ Here, we'll create a class to take care of _early-stopping_"
      ],
      "metadata": {
        "id": "qbVeTx7Sgsr6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile helper_modules/utils.py\n",
        "\"\"\"\n",
        "contains helper functions for tasks like loading & saving models,\n",
        "earlystopping, plotting training metrics, e.t.c\n",
        "\"\"\"\n",
        "import torch, pathlib, numpy as np, matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "from torch.utils.data import Dataset, Subset\n",
        "from pathlib import Path\n",
        "from copy import deepcopy\n",
        "\n",
        "# declarea class to implement earlystopping\n",
        "class EarlyStopping:\n",
        "  \"\"\"A class that implements EarlyStopping mechanism\n",
        "\n",
        "  Parameters\n",
        "  -------\n",
        "    score_type:\n",
        "      'metric' for a metric score (eg. f1_score) and 'loss' for\n",
        "        a loss function (eg. CrossEntropyLoss)\n",
        "\n",
        "    min_delta: float\n",
        "      How much of a difference in loss is to be considered worthy to continue training\n",
        "\n",
        "    patience: int\n",
        "      The number of epochs to wait after the last improvement before stopping\n",
        "  \"\"\"\n",
        "  def __init__(self, score_type:str, min_delta:float=0.0, patience:int=5): # constructor\n",
        "    self.counter = 0\n",
        "    self.patience = patience\n",
        "    self.min_delta = min_delta\n",
        "    self.score_type = score_type\n",
        "    self.best_epoch = None\n",
        "    self.best_score = None\n",
        "    self.best_state_dict = None\n",
        "    self.stop_early = False\n",
        "\n",
        "    if (self.score_type != 'metric') and (self.score_type != 'loss'):\n",
        "      err_msg = 'score_type can only be \"metric\" or \"loss\"'\n",
        "      raise Exception(err_msg)\n",
        "\n",
        "  def __call__(self, model:torch.nn.Module, ep:int, ts_score:float):\n",
        "    \"\"\"Pass the following arguments to the object name of EarlyStopping to call this method\n",
        "\n",
        "    Parameters\n",
        "    -------\n",
        "      model: torch.nn.Module\n",
        "          The object name of the model being trained (subclasses nn.Module)\n",
        "\n",
        "      ep: int\n",
        "          The current epoch in the training / optimization loop\n",
        "\n",
        "      ts_score: float\n",
        "          The score (loss or metric) being used to decide early stopping mechanism\n",
        "    \"\"\"\n",
        "    if self.best_epoch is None: # for first time:\n",
        "      self.best_epoch = ep # store current epoch\n",
        "      self.best_score = ts_score # store current loss as best loss\n",
        "      # make a copy of current model's state_dict\n",
        "      self.best_state_dict = deepcopy(model.state_dict())\n",
        "\n",
        "    # if previous loss - current loss exceeds min_delta: (for loss function)\n",
        "    elif (self.best_score - ts_score >= self.min_delta) and (self.score_type == 'loss'):\n",
        "      self.best_epoch = ep # store current epoch\n",
        "      self.best_score = ts_score # store current loss as best\n",
        "      # make a copy of current model's state_dict\n",
        "      self.best_state_dict = deepcopy(model.state_dict())\n",
        "      self.counter = 0 # restore counter to zero\n",
        "\n",
        "    # if current metric - previous. metric exceeds min_delta: (for metric)\n",
        "    elif (ts_score - self.best_score >= self.min_delta) and (self.score_type == 'metric'):\n",
        "      self.best_epoch = ep # store current epoch\n",
        "      self.best_score = ts_score # store current loss as best\n",
        "      # make a copy of current model's state_dict\n",
        "      self.best_state_dict = deepcopy(model.state_dict())\n",
        "      self.counter = 0 # restore counter to zero\n",
        "\n",
        "    else: # otherwise\n",
        "      self.counter += 1 # increment counter each time\n",
        "      if self.counter >= self.patience:\n",
        "        self.stop_early = True"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pBFIugk9grLk",
        "outputId": "72d5d04f-997f-4b74-8f77-2a50968c3371"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing helper_modules/utils.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model training / evaluation\n",
        "> Here, I'll define functions for training and testing batches of data, as well as a function to return prediction labels, `y_pred` and prediction probabilities `y_proba`"
      ],
      "metadata": {
        "id": "YuOR_grSikbB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile helper_modules/train_test.py\n",
        "import torch, numpy as np\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "\n",
        "# del torch, F, f1_score, accuracy_score\n",
        "\n",
        "# function for model training\n",
        "def train_batches(model:torch.nn.Module, train_dl:torch.utils.data.DataLoader,\n",
        "                optimizer:torch.optim.Optimizer, loss_fn:torch.nn.Module, device:str) -> tuple[float, float, float]:\n",
        "  \"\"\"Trains model on all batches of train-set DataLoader and returns\n",
        "      average training loss, accuracy and f1_score\n",
        "\n",
        "  Parameters\n",
        "  -------\n",
        "    model: torch.nn.Module\n",
        "        The model being trained\n",
        "\n",
        "    train_dl: torch.utils.data.DataLoader\n",
        "        DataLoader for training data\n",
        "\n",
        "    optimizer: torch.optim.Optimizer\n",
        "        The optimizer\n",
        "\n",
        "    loss_fn: torch.nn.Module\n",
        "        Function used to calculate loss\n",
        "\n",
        "    device: str\n",
        "        The device on which computation occurs\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "    ls: float\n",
        "        average test loss across all batches of data\n",
        "    acc: float\n",
        "        average test accuracy across all batches of data\n",
        "    f1: float\n",
        "        average test f1_score across all batches of data\n",
        "  \"\"\"\n",
        "  # for reproducability\n",
        "  torch.manual_seed(0)\n",
        "  torch.cuda.manual_seed(0)\n",
        "  ls, acc, f1 = 0, 0, 0\n",
        "\n",
        "  #training mode\n",
        "  model.train()\n",
        "\n",
        "  for x, y in train_dl:\n",
        "    # move x, y to device\n",
        "    x, y = x.to(device), y.to(device)\n",
        "    # zero_grad\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # forward pass\n",
        "    logits = model(x)\n",
        "    y_pred = F.softmax(logits, dim=1).argmax(dim=1).cpu().numpy()\n",
        "\n",
        "    # loss\n",
        "    loss = loss_fn(logits, y)\n",
        "    # accumulate values\n",
        "    ls += loss.item()\n",
        "    acc += accuracy_score(y_true=y.cpu().numpy(), y_pred=y_pred)\n",
        "    f1 += f1_score(y_true=y.cpu().numpy(), y_pred=y_pred)\n",
        "\n",
        "    # back propagation\n",
        "    loss.backward()\n",
        "    # optmizer step\n",
        "    optimizer.step()\n",
        "\n",
        "  # compute averages\n",
        "  ls /= len(train_dl)\n",
        "  acc /= len(train_dl)\n",
        "  f1 /= len(train_dl)\n",
        "\n",
        "  # return values\n",
        "  return ls, acc, f1\n",
        "\n",
        "# function for model testing\n",
        "def test_batches(model:torch.nn.Module, test_dl:torch.utils.data.DataLoader,\n",
        "                loss_fn:torch.nn.Module, device:str) -> tuple[float, float, float]:\n",
        "  \"\"\"Evaluates model on all batches of test-set DataLoader and returns\n",
        "      average test loss, accuracy and f1_score\n",
        "\n",
        "  Parameters\n",
        "  -------\n",
        "    model: torch.nn.Module\n",
        "        The model being evaluated\n",
        "\n",
        "    test_dl: torch.utils.data.DataLoader\n",
        "        DataLoader for test data\n",
        "\n",
        "    loss_fn: torch.nn.Module\n",
        "        Function used to calculate loss\n",
        "\n",
        "    device: str\n",
        "        The device on which computation occurs\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "    ls: float\n",
        "        average test loss across all batches of data\n",
        "    acc: float\n",
        "        average test accuracy across all batches of data\n",
        "    f1: float\n",
        "        average test f1_score across all batches of data\n",
        "  \"\"\"\n",
        "  ls, f1, acc = 0, 0, 0\n",
        "\n",
        "  # evaluation-mode\n",
        "  model.eval()\n",
        "\n",
        "  with torch.inference_mode():\n",
        "    for x, y in test_dl:\n",
        "      # move x, y to device\n",
        "      x, y = x.to(device), y.to(device)\n",
        "\n",
        "      # forward pass\n",
        "      logits = model(x)\n",
        "      y_pred = F.softmax(logits, dim=1).argmax(dim=1).cpu().numpy()\n",
        "\n",
        "      # loss\n",
        "      loss = loss_fn(logits, y)\n",
        "\n",
        "      # accumulate values\n",
        "      ls += loss.item()\n",
        "      acc += accuracy_score(y_true=y.cpu().numpy(), y_pred=y_pred)\n",
        "      f1 += f1_score(y_true=y.cpu().numpy(), y_pred=y_pred)\n",
        "\n",
        "  # compute averages\n",
        "  ls /= len(test_dl)\n",
        "  acc /= len(test_dl)\n",
        "  f1 /= len(test_dl)\n",
        "\n",
        "  # return values\n",
        "  return ls, acc, f1\n",
        "\n",
        "# function to return prediction labels (y_pred) and prediction probabilities (y_proba)\n",
        "def get_preds_proba(model:torch.nn.Module, test_dl:torch.utils.data.DataLoader,\n",
        "                    device:str) -> tuple[np.ndarray, np.ndarray]:\n",
        "  \"\"\"A function that returns y_pred and y_proba from the passed DataLoader\n",
        "\n",
        "  Parameters\n",
        "  -------\n",
        "    model: torch.nn.Module\n",
        "        A neural network that subclasses torch.nn.Module\n",
        "\n",
        "    test_dl: torch.utils.data.DataLoader\n",
        "        A DataLoader for the test dataset\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "    y_pred: np.ndarray\n",
        "        A numpy ndarray with prediction labels\n",
        "\n",
        "    y_proba: np.ndarray\n",
        "        A numpy ndarray with prediction probabilities\n",
        "  \"\"\"\n",
        "  # empty lists\n",
        "  y_preds, y_proba = list(), list()\n",
        "  with torch.inference_mode():\n",
        "    model.eval() # set eval mode\n",
        "    for x, _ in test_dl:\n",
        "      # move x to device\n",
        "      x = x.to(device)\n",
        "\n",
        "      # make prediction\n",
        "      logits = model(x)\n",
        "\n",
        "      # prediction and probabilites\n",
        "      proba = F.softmax(logits, dim=1)\n",
        "      pred = F.softmax(logits, dim=1).argmax(dim=1)\n",
        "\n",
        "      # append\n",
        "      y_preds.append(pred)\n",
        "      y_proba.append(proba)\n",
        "\n",
        "  y_preds = torch.concatenate(y_preds).cpu().numpy()\n",
        "  y_proba = torch.concatenate(y_proba).cpu().numpy()\n",
        "\n",
        "  return y_preds, y_proba"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wS8b1rYQjWfk",
        "outputId": "83dd62d5-a019-4baa-9e0f-4520b07b682e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing helper_modules/train_test.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plot results\n",
        "> Here, I'll define helper functions for plotting training metrics"
      ],
      "metadata": {
        "id": "GE2tc9RUahxx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile -a helper_modules/utils.py\n",
        "\n",
        "# function to plot train and test results\n",
        "def plot_train_results(ep_list:list, train_score:list, test_score:list,\n",
        "                       ylabel:str, title:str, best_epoch:int):\n",
        "  \"\"\"A function that plots train and test results against each other\n",
        "\n",
        "  Parameters\n",
        "  -------\n",
        "    ep_list: list\n",
        "      A list containing all epochs used in the optimization loop\n",
        "\n",
        "    train_score: list\n",
        "      A list containing a specific training score from the optimization loop\n",
        "\n",
        "    test_score: list\n",
        "      A list containing a specific training score from the optimization loop\n",
        "\n",
        "    y_label: str\n",
        "      y-axis label for the plot\n",
        "\n",
        "    title: str\n",
        "      Title for the plot\n",
        "\n",
        "    best_epoch: int\n",
        "      Best epoch for which early stopping occurred\n",
        "  \"\"\"\n",
        "  f, ax = plt.subplots(figsize=(5, 3), layout='constrained')\n",
        "\n",
        "  # train loss\n",
        "  ax.plot(ep_list, train_score, label='Training',\n",
        "          linewidth=1.7, color='#0047ab')\n",
        "\n",
        "  # test loss\n",
        "  ax.plot(ep_list, test_score, label='Validation',\n",
        "          linewidth=1.7, color='#990000')\n",
        "  # vertical line (for early stopping)\n",
        "  if best_epoch is not None:\n",
        "    ax.axvline(best_epoch, linestyle='--', color='#000000', linewidth=1.0,\n",
        "             label=f'Best ep ({best_epoch})')\n",
        "\n",
        "  # axis, title\n",
        "  ax.set_title(title, weight='black')\n",
        "  ax.set_ylabel(ylabel)\n",
        "  ax.set_xlabel('Epoch')\n",
        "  ax.tick_params(axis='both', labelsize=9)\n",
        "  plt.grid(color='#e5e4e2')\n",
        "\n",
        "  # legend\n",
        "  f.legend(fontsize=9, loc='upper right',\n",
        "          bbox_to_anchor=(1.28, 0.93),\n",
        "          fancybox=False)\n",
        "\n",
        "  plt.show()\n",
        "\n",
        "# function to plot confusion matrix\n",
        "def plot_confusion_matrix(y_true:np.ndarray, y_pred:np.ndarray):\n",
        "  \"\"\"A function that plots Confusion Matrix for all classes\n",
        "\n",
        "  Parameters\n",
        "  -------\n",
        "    y_true: np.ndarray\n",
        "      An ndarray containing true label values\n",
        "\n",
        "    y_pred: np.ndarray\n",
        "      An ndarray containing predicted label values\n",
        "  \"\"\"\n",
        "  # define figure and plot\n",
        "  _, ax = plt.subplots(figsize=(3.0,3.0), layout='compressed')\n",
        "  # plot\n",
        "  ConfusionMatrixDisplay.from_predictions(\n",
        "      y_true=y_true,\n",
        "      y_pred=y_pred, cmap='Blues', colorbar=False, ax=ax)\n",
        "\n",
        "  # set x and y labels\n",
        "  ax.set_ylabel('True Labels', weight='black')\n",
        "  ax.set_xlabel('Predicted Labels', weight='black',\n",
        "                  color='#dc143c')\n",
        "  # set tick size and position\n",
        "  ax.xaxis.tick_top()\n",
        "  ax.xaxis.set_label_position('top')\n",
        "  ax.tick_params(axis='both', labelsize=9)\n",
        "\n",
        "  # change annotation font\n",
        "  for txt in ax.texts:\n",
        "    txt.set_fontsize(9)\n",
        "\n",
        "  plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pkoLlplHakM9",
        "outputId": "defda377-f381-48f5-c9aa-ab686d4f0efd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Appending to helper_modules/utils.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save model\n",
        "> 🔔 **Info**\n",
        "\n",
        "> Pytorch's recommended way of saving a model is by saving its [`state_dict`](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.state_dict). To do this, the [documentation](https://pytorch.org/tutorials/beginner/saving_loading_models.html#save-load-state-dict-recommended) recommends calling [`torch.save(obj=model.state_dict(), f=PATH)`](https://pytorch.org/docs/stable/generated/torch.save.html#torch-save)\n",
        "+ `f` - a file-like object or a string or `os.PathLike` object containing a file name. To work with paths, we'll use Python's [`pathlib`](https://docs.python.org/3/library/pathlib.html) module\n",
        "+ A common PyTorch convention is to save models using either a `.pt` or `.pth` file extension\n",
        "+ Also, it's good practice to move the model to the `cpu` before saving its `state_dict`"
      ],
      "metadata": {
        "id": "q8dmvDKZjJco"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile -a helper_modules/utils.py\n",
        "\n",
        "# function to save model to specified directory\n",
        "def save_model(model:torch.nn.Module, path:pathlib.PosixPath):\n",
        "  \"\"\"Function to save model to a specified path\n",
        "\n",
        "  Parameters\n",
        "  -------\n",
        "    model: torch.nn.Module\n",
        "      The model to save\n",
        "\n",
        "    path: pathlib.PosixPath\n",
        "      Path to save model's state_dict\n",
        "  \"\"\"\n",
        "  torch.save(obj=model.cpu().state_dict(), f=path)\n",
        "  print(f\"MODEL'S state_dict SAVED TO: {path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KzvslsO4nTJL",
        "outputId": "3249c53a-969f-4067-ccbc-4d4e0bd698e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Appending to helper_modules/utils.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load saved model\n",
        "> To load a previously saved model's `state_dict`, we call\n",
        " [`torch.load(f=PATH, weights_only=True)`](https://pytorch.org/docs/stable/generated/torch.load.html#torch.load) that loads an object saved using [`torch.save()`](https://pytorch.org/docs/stable/generated/torch.save.html#torch-save) from a file:\n",
        "\n",
        "```\n",
        "    model = TheModelClass(*args, **kwargs)\n",
        "    model.load_state_dict(torch.load(PATH, weights_only=True))\n",
        "    model.eval()\n",
        "```\n",
        "\n",
        "> 🔔 **Info**\n",
        "+ Remember that you must call `model.eval()` before running inference\n",
        "+ `f` - a file-like object or a string or `os.PathLike` object containing a file name. To work with paths, we'll use Python's [`pathlib`](https://docs.python.org/3/library/pathlib.html) module\n",
        "+ Note that a `model` class must have been defined earlier, before calling [`model.load_state_dict()`](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.load_state_dict) on the object"
      ],
      "metadata": {
        "id": "5f5k3J5rcAlP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile -a helper_modules/utils.py\n",
        "\n",
        "# function to load model from a specified path\n",
        "def load_model(model:torch.nn.Module, path:pathlib.PosixPath):\n",
        "  \"\"\"Function to load model from a specified path\n",
        "\n",
        "  Parameters\n",
        "  -------\n",
        "    model:torch.nn.Module\n",
        "        A new object of the model class\n",
        "\n",
        "    path:pathlib.PosixPath\n",
        "        Path pointing to a previously saved model's state_dict\n",
        "\n",
        "  Return\n",
        "  -------\n",
        "    model:torch.nn.Module\n",
        "      model returned after loading state_dict\n",
        "  \"\"\"\n",
        "  # overwrite stat_dict\n",
        "  model.load_state_dict(\n",
        "      torch.load(f=path, weights_only=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MLlas76CcGLJ",
        "outputId": "ec5132c3-c3e6-4257-f596-6de9a7e2a95e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Appending to helper_modules/utils.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Make inference\n",
        "> Here, I'll declare functions to make inference:\n",
        "+ On a single random image\n",
        "+ On multiple `(12)` random images"
      ],
      "metadata": {
        "id": "qiK8QJ57hASq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile -a helper_modules/utils.py\n",
        "\n",
        "# function to make inference on a single random image\n",
        "def make_single_inference(model:torch.nn.Module, dataset:torch.utils.data.Dataset,\n",
        "                          label_map:dict, device:str):\n",
        "  \"\"\"Makes inference using a random data point from the test dataset\n",
        "\n",
        "  Parameters\n",
        "  -------\n",
        "    model: torch.nn.Module\n",
        "      A model (subclassing torch.nn.Module) to make inference\n",
        "\n",
        "    dataset: torch.utils.data.Dataset\n",
        "      The Dataset to use for testing purposes\n",
        "\n",
        "    label_map: dict\n",
        "      A dictionary maping indices to labels (eg. {0:'O', 1:'X'})\n",
        "\n",
        "    device: str\n",
        "      Device on which to perform computation\n",
        "  \"\"\"\n",
        "  # get random image from test_set\n",
        "  idx = np.random.choice(len(dataset))\n",
        "  img, lb = dataset[idx]\n",
        "\n",
        "  # make prediction\n",
        "  with torch.inference_mode():\n",
        "    model.to(device) # move model to device\n",
        "    model.eval() # set eval mode\n",
        "    lgts = model.to(device)(img.unsqueeze(0).to(device))\n",
        "    pred = F.softmax(lgts, dim=1).argmax(dim=1)\n",
        "\n",
        "  # print actual retrieved image\n",
        "  plt.figure(figsize=(1.0, 1.0))\n",
        "  # title with label\n",
        "  if pred==lb:\n",
        "    plt.title(\n",
        "        f'Actual: {label_map[lb]}\\nPred: {label_map[pred.item()]}',\n",
        "        fontsize=8)\n",
        "  else: # if labels do not match, title = with red colour\n",
        "    plt.title(\n",
        "        f'Actual: {label_map[lb]}\\nPred: {label_map[pred.item()]}',\n",
        "        fontsize=8, color='#de3163', weight='black')\n",
        "  plt.axis(False)\n",
        "  plt.imshow(img.squeeze(), cmap='gray')\n",
        "  plt.show()\n",
        "\n",
        "# function to make inference on multiple random images\n",
        "def make_multiple_inference(model:torch.nn.Module, dataset:torch.utils.data.Dataset,\n",
        "                            label_map:dict, device:str):\n",
        "  \"\"\"Makes inference using a random data point from the test dataset\n",
        "\n",
        "  Parameters\n",
        "  -------\n",
        "    model: torch.nn.Module\n",
        "      A model (subclassing torch.nn.Module) to make inference\n",
        "\n",
        "    dataset: torch.utils.data.Dataset\n",
        "      The Dataset used for evaluation purposes\n",
        "\n",
        "    label_map: dict\n",
        "      A dictionary maping indices to labels (eg. {0:'O', 1:'X'})\n",
        "\n",
        "    device: str\n",
        "      Device on which to perform computation\n",
        "  \"\"\"\n",
        "  # get array of 12 random indices of images in test_dataset\n",
        "  indices = np.random.choice(len(dataset),\n",
        "                                  size= 12, replace=False)\n",
        "  # create subset from the 12 indices\n",
        "  sub_set = Subset(dataset=dataset, indices=indices)\n",
        "\n",
        "  # define a figure and subplots\n",
        "  f, axs = plt.subplots(2, 6, figsize=(6,5), layout='compressed')\n",
        "\n",
        "  # move model to device & set eval mode\n",
        "  model.to(device)\n",
        "  model.eval()\n",
        "\n",
        "  # loop through each subplot\n",
        "  for i, ax in enumerate(axs.flat):\n",
        "    img, lb = sub_set[i] # return image and label\n",
        "\n",
        "    # make inference on image retuned\n",
        "    with torch.inference_mode():\n",
        "      lg = model(img.unsqueeze(0).to(device))\n",
        "      pred = F.softmax(lg, dim=1).argmax(dim=1)\n",
        "\n",
        "    ax.imshow(img.squeeze(), cmap='gray')\n",
        "    ax.axis(False)\n",
        "    if pred==lb:\n",
        "      ax.set_title(\n",
        "          f'Actual: {label_map[lb]}\\nPred: {label_map[pred.item()]}',\n",
        "          fontsize=8)\n",
        "    else: # if labels do not match, title = with red colour\n",
        "      ax.set_title(\n",
        "          f'Actual: {label_map[lb]}\\nPred: {label_map[pred.item()]}',\n",
        "          fontsize=8, color='#de3163', weight='black')\n",
        "\n",
        "  f.suptitle('Inference Made on 12 Random Test Images',\n",
        "            weight='black',\n",
        "            y=0.83)\n",
        "  plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJ0t1UlRhDHP",
        "outputId": "d2ecfe96-ae77-4c08-887d-99b234a9397a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Appending to helper_modules/utils.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Archive modules\n",
        "> Here, we'll create a function to archive all the modules `*.py` files into a `*.zip` file with the help of the [`zipfile`](https://docs.python.org/3/library/zipfile.html) python module\n",
        "\n",
        "> ✋ **Info**\n",
        "+ The `zip` file containing the helper modules will be then uploaded to the GitHub repository [here](https://github.com/Martinmbiro/XO-binary-classification/tree/main/helper%20modules). That way, the modules can be downloaded and extracted dynamically in code"
      ],
      "metadata": {
        "id": "KyrG_C_hni52"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile, pathlib\n",
        "\n",
        "def archive_modules(path_to_files:pathlib.PosixPath, zip_name:str):\n",
        "  \"\"\"Takes a path with files and archives .py files in that path\n",
        "  Parameters\n",
        "  -------\n",
        "    path_to_files: path_to_files:pathlib.PosixPath\n",
        "      path to the directory in question\n",
        "    zip_name: str\n",
        "      Name to give the zipfolder\n",
        "  \"\"\"\n",
        "  with zipfile.ZipFile(file=zip_name, mode='w', compression=zipfile.ZIP_STORED) as zipf:\n",
        "    for file_path in path_to_files.glob('*.py'):\n",
        "        zipf.write(filename=file_path, arcname=file_path.name)"
      ],
      "metadata": {
        "id": "xjfGfN7BZ9CK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# archive modules\n",
        "archive_modules(modules_dir, 'modules.zip')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hGGwUg_ebUDI",
        "outputId": "589e10f8-376e-48ee-bf02-5208fe018c5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1.85 ms, sys: 0 ns, total: 1.85 ms\n",
            "Wall time: 2.14 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> ▶️ **Up Next**\n",
        "+ Having created modules out of the most reusable code, I'll implement an end to tend project for classifying `X` and `O` images in the subsequent notebook, `01. XO Culimination.ipynb`"
      ],
      "metadata": {
        "id": "huE7PJuzGBva"
      }
    }
  ]
}